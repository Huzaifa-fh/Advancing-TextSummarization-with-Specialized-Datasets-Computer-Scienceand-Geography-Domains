{"type": "failure", "doc_id": 0, "question": "True", "candidate_answer_from_summary": "the term", "qa_answer_from_source": "", "squad_f1": 0.0, "failure_reason": "empty_qa_answer", "qg_model": "iarfmoose/t5-base-question-generator", "qa_model": "deepset/roberta-base-squad2", "summary_sentence_used_for_qg": "the term \" \" \" in the language language \" is used to refer refer to a sentence in which the verb is a verb in a sentence.", "source_excerpt_around_qa_answer": "Word embeddings extract semantic features of words from large datasets of text.\n Most embedding methods rely on a log-bilinear model to predict the occurrence\n of a word in a context of other words. Here we propose word2net, a method that\n "}
{"type": "failure", "doc_id": 1, "question": "True", "candidate_answer_from_summary": "the context", "qa_answer_from_source": "", "squad_f1": 0.0, "failure_reason": "empty_qa_answer", "qg_model": "iarfmoose/t5-base-question-generator", "qa_model": "deepset/roberta-base-squad2", "summary_sentence_used_for_qg": "in the context of genetic algorithms, genetic algorithms attempt to learn how the language is generated from a corpus of datasets, such as text classification, text classification and text retrieval.", "source_excerpt_around_qa_answer": "Natural language is hierarchically structured: smaller units (e.g., phrases) are nested within larger units (e.g., clauses). When a larger constituent ends, all of the smaller constituents that are nested within it must also be closed. Whil"}
{"type": "failure", "doc_id": 2, "question": "True", "candidate_answer_from_summary": "the concept", "qa_answer_from_source": "", "squad_f1": 0.0, "failure_reason": "empty_qa_answer", "qg_model": "iarfmoose/t5-base-question-generator", "qa_model": "deepset/roberta-base-squad2", "summary_sentence_used_for_qg": "the concept of the agent's ability to perceive the environment, especially when when the agent has no information about the environment.", "source_excerpt_around_qa_answer": "Neural networks make mistakes. The reason why a mistake is made often remains a mystery. As such neural networks often are considered a black box. It would be useful to have a method that can give an explanation that is intuitive to a user "}
