{"type": "failure", "doc_id": 0, "question": "True", "candidate_answer_from_summary": "linear", "qa_answer_from_source": "", "squad_f1": 0.0, "failure_reason": "empty_qa_answer", "qg_model": "iarfmoose/t5-base-question-generator", "qa_model": "deepset/roberta-base-squad2", "summary_sentence_used_for_qg": "Word2net, a method that combines linear parametrization with neural networks, employs hierarchical organization of word networks to incorporate additional meta-data into the embedding model.", "source_excerpt_around_qa_answer": "Word embeddings extract semantic features of words from large datasets of text.\n Most embedding methods rely on a log-bilinear model to predict the occurrence\n of a word in a context of other words. Here we propose word2net, a method that\n "}
{"type": "failure", "doc_id": 1, "question": "True", "candidate_answer_from_summary": "Natural language", "qa_answer_from_source": "", "squad_f1": 0.0, "failure_reason": "empty_qa_answer", "qg_model": "iarfmoose/t5-base-question-generator", "qa_model": "deepset/roberta-base-squad2", "summary_sentence_used_for_qg": "Natural language is hierarchically structured, with smaller units nested within larger units.", "source_excerpt_around_qa_answer": "Natural language is hierarchically structured: smaller units (e.g., phrases) are nested within larger units (e.g., clauses). When a larger constituent ends, all of the smaller constituents that are nested within it must also be closed. Whil"}
{"type": "failure", "doc_id": 2, "question": "True", "candidate_answer_from_summary": "Gradient Descent", "qa_answer_from_source": "", "squad_f1": 0.0, "failure_reason": "empty_qa_answer", "qg_model": "iarfmoose/t5-base-question-generator", "qa_model": "deepset/roberta-base-squad2", "summary_sentence_used_for_qg": "A method for explaining the mistakes of a classifier model by visually showing what must be added to an image such that it is correctly classified is called Gradient Descent on the input, which combines adversarial examples, generative modeling and a correction technique based on difference target propagation to create a technique that creates explanations of why an image is misclassified.", "source_excerpt_around_qa_answer": "Neural networks make mistakes. The reason why a mistake is made often remains a mystery. As such neural networks often are considered a black box. It would be useful to have a method that can give an explanation that is intuitive to a user "}
